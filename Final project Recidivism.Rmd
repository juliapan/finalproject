---
title: "Recidivism - MA415/615 Final Project"
subtitle: "Julia Pan, Eesha Pendharkar"
output:
  word_document: default
  pdf_document: default
authors: "Julia Pan, Eesha Pendharkar"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RSQLite)
library(sqldf)
library(dplyr)
library(tidyr)
library(reshape)
library(ggplot2)
library(tidyverse)
library(maps)
library(tidytext)
library(pdftools)
library(wordcloud)
library(devtools)
library(twitteR)
library(ROCR)
```
## Introduction

In this report we will use data from Broward County, Florida to examine how COMPAS, a risk assessment instrument widely used in the US, predicts recidivism (tendency to reoffend) among offenders. The COMPAS questionnaire collects information on offenders, including past criminal offenses, substance abuse, family history, social connections, etc. to produce risk scores. These risk scores are categorized into three sections: Low, Medium, and High Risk. We will look at the rates of recidivism among each of these three groups across various ethnicities to determine the efficacy of this instruments for different ethnic groups. 

Additionally, we will perform a textual and sentiment analysis using various sources about the meaning of recidivism and why it is a concern in the criminal justice world. We have visualized the most commonly used words to capture the difference in sentiment and tone by the government vs the media. 

## Crime Rates in the US

A major incentive for the development of risk assessment models and algorithms in the criminal justice system was the over-saturated penal system in the US. The map below shows the rate of violent crime in each state in 2014. Darker hues indicate higher crime rates. The Shiny app will demonstrate average crime rates over a selected time period, for a wider range of crimes. 

```{r,echo=FALSE, include=FALSE }

# Reading in data file and cleaning up column names/information
map <- read.csv(file = "CrimeStatebyState.csv")
map <- map[,1:12]
map$Pop <- NULL
colnames(map) <- c("region","Year","Violent", "Murder/Non-negligent Manslaughter",
                   "Rape", "Robbery","Aggravated Assault","Property Crime",
                   "Burglary","Larceny Theft","Motor Vehicle Theft")

# Gather crime columns
map <- map %>%
  gather(key="Type_of_Crime",value = "Crime_Rate",`Violent`:`Motor Vehicle Theft`)

map <- map[!map$region=="US - Total",]
map$region <- sapply(map$region,tolower)
map$region[map$region=="dc"] <- "district of columbia"

# Retrieve coordinates to create US Map, filter dataset and merge
states <- map_data("state")
map <- filter(map,Year == 2014 & Type_of_Crime=="Violent")
maptotal <- merge(states,map,by="region")
```

```{r,echo=FALSE}

ggplot() + 
  geom_polygon(data=maptotal, aes(x=long, y=lat, group = group, fill=Crime_Rate),colour="white") + 
  scale_fill_continuous(low = "thistle2", high = "darkred", guide="colorbar")+
  ggtitle("Violent Crime Rates Per State in 2014")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y=element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_blank())
```


```{r, echo=FALSE,include=FALSE}

compas <- "compas.db"
sqlite.driver <- dbDriver("SQLite")
db <- dbConnect(sqlite.driver,dbname=compas)

casearrest <- dbGetQuery(db, 'SELECT * FROM casearrest')
charge <- dbGetQuery(db,'SELECT * FROM charge')
compas <- dbGetQuery(db,'SELECT * FROM compas')
jailhistory <- dbGetQuery(db,'SELECT * FROM jailhistory')
people <- dbGetQuery(db,'SELECT * FROM people')
prisonhistory <- dbGetQuery(db,'SELECT * FROM prisonhistory')
summary <- dbGetQuery(db,'SELECT * FROM summary')
dbDisconnect(db)

compas$name <- paste(compas$first,compas$last)
compas <- compas[compas$type_of_assessment == "Risk of Recidivism",]

compas_one <- compas[!duplicated(compas$person_id),]

people <- sqldf("SELECT people.* , compas_one.person_id
                FROM people
                LEFT JOIN compas_one ON people.first=compas_one.first 
                AND people.last=compas_one.last")
people <- people[!duplicated(people$id),]

# Look only at cases within 30 days of COMPAS assessment
casearrest <- casearrest[casearrest$days_since_compas_arrest>= -30 & 
                          casearrest$days_since_compas_arrest <= 30,]
casearrest <- casearrest[!duplicated(casearrest[,c("charge_degree","person_id")]),]
casearrest <- casearrest[!casearrest$charge_degree == "(0)",]
charge$case_type <- NULL
charge <- charge[charge$days_since_compas >= -30 & charge$days_since_compas <= 30,]
charge <- charge[!charge$charge_degree == "(0)",]

A <- aggregate(casearrest$charge_degree,list(casearrest$person_id),
                          paste,collapse=" ")
colnames(A) <- c("person_id","charges")


```

```{r,echo=FALSE,include=FALSE }

# Creating base dataframe with relevant information
data <- compas[,c("person_id","first","last","type_of_assessment","score_text")]
data <- data[data$type_of_assessment == "Risk of Recidivism",]

data <- sqldf("SELECT data.*, people.c_charge_degree, people.c_charge_desc,
              people.is_recid, people.race
              FROM data
              JOIN people ON data.person_id = people.person_id")

data <- data[data$is_recid != -1,]
data <- data[data$score_text != "N/A",]
data <- data[!duplicated(data$person_id),]

# Looking at percentage of recidivists per score category
sum_scores <- aggregate(is_recid ~ score_text, data=data, sum)
totalbyscore <- aggregate(rep(1,length(data$score_text)),by=list(data$score_text),sum)
colnames(totalbyscore) <- c('score','total')
sum_scores <- cbind(sum_scores,totalbyscore)
sum_scores$score <- NULL
sum_scores <- sum_scores %>% slice(match(c("Low","Medium","High"),score_text))
sum_scores$percentage <- (sum_scores$is_recid / sum_scores$total)*100

# Percentage of recidivists per score category, by race
race <- aggregate(is_recid ~ score_text + race, data=data, sum)
race.total <- aggregate(person_id ~ score_text + race, data=data, FUN=length)
race$total <- race.total$person_id
race$nonrecid <- race$total - race$is_recid
race$prop <- race$is_recid / race$total * 100
table <- cast(race,race~score_text)
table <- table[,c(1,3,4,2)]

totalbyrace <- sqldf("SElECT race, count(race)
                     FROM data
                     GROUP BY race")

joinrace <- sqldf("SELECT race.*, totalbyrace.`count(race)`
              FROM race
                INNER JOIN totalbyrace on race.race=totalbyrace.race")

race <- joinrace
race$propbyrace <- race$is_recid / race$`count(race)` * 100
race$propnonrecid <- race$nonrecid / race$`count(race)` *100

# Creating bar charts for proportion of recidivists in each score category, across race
high <- subset(race,score_text=="High")
medium <- subset(race,score_text=="Medium")
low <- subset(race,score_text=="Low")

```

## Population Summary

Now, we will examine recidivism rates in Broward County, Florida. Before we begin our analysis, let's look at general summary information to frame our conclusions. In this dataset, we are examining 10,892 individuals. Of these, 3,652 did recidivate. The charts below demonstrate the demographics of this population by score category and race. 

```{r, echo=FALSE}

data$score_text <- factor(data$score_text,levels=c("Low","Medium","High"))
barplot(table(data$score_text),main="Frequency of COMPAS Scores",
        xlab="COMPAS Score",
        ylab="Frequency")

plot <- barplot(table(data$race),main="Frequency of Offenders by Race",
        xlab="Race",
        ylab="Frequency",
        axisnames=FALSE)
text(plot, par("usr")[3], labels = names(table(data$race)), srt = 45, adj = c(1.1,1.1), 
     xpd = TRUE, cex=.9)

```


## Recidivists by Risk Score

Next, let's look at the breakdown of each risk score category by race. We can see that there is a high percentage of Asians and Native Americans who received high risk scores, though the low representation of these ethnicities in this dataset should be recognized. Seeing as African-Americans make up a majority of this dataset, the high correlation between high risk score and high rate of recidivism is significant. For medium COMPAS scores, the proportion of recidivists is relatively constant across ethnicities. Though Asians have a lower rate of recidivists among Low-risk individuals, they again make up a small portion of the total population in this dataset. 


```{r, echo=FALSE}

ggplot(data=high)+
  geom_bar(aes(x=race,y=prop),stat="identity")+
  ylim(0,100)+
  ggtitle("High COMPAS Score")+
  xlab("Race")+
  ylab("Proportion")

ggplot(data=medium)+
  geom_bar(aes(x=race,y=prop),stat="identity")+
  ggtitle("Medium COMPAS Score")+
  ylim(0,100)+
  xlab("Race")+
  ylab("Proportion")

ggplot(data=low)+
  geom_bar(aes(x=race,y=prop),stat="identity")+
  ggtitle("Low COMPAS Score")+
  ylim(0,100)+
  xlab("Race")+
  ylab("Proportion")

```

### Comparing Recidivists and Non-Recidivists

Here, we will look at the proportion of recidivists and non-recidivists through stacked bar charts. In the first chart, we can see that African-Americans and Native-Americans have the highest total rate of recidivism as well as the most individuals with High risk scores. More compelling, however, is the second chart which shows risk scores for non-recidivists. It is clear that African-Americans receive high risk scores more frequently than any other ethnicity for offenders who do not recidivate. This could indicate a racial bias in the risk assessment instrument. 

```{r, echo=FALSE}
# Creating bar charts for nonrecid and recid for score category across race
prop <- subset(race,select=c("score_text","race","propbyrace","propnonrecid"))
colnames(prop) <- c("score_text","race","recid","nonrecid")
prop <- prop %>% gather(`recid`,`nonrecid`,key = "recid",value="prop")
recid_prop <- prop[prop$recid == "recid",]
recid_prop$recid <- NULL
nonrecid <- prop[prop$recid=="nonrecid",]
nonrecid$recid <- NULL

ggplot(data=recid_prop)+
  geom_bar(aes(x=race,y=prop,fill=factor(score_text,levels=c("Low","Medium","High"))),
               stat="identity")+
  scale_fill_grey(start=0.8, end=0.2, name="Legend")+
  ggtitle("Proportion of Recidivists By COMPAS Score")+
  xlab("Race")+
  ylab("Proportion (%)")+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))


ggplot(data=nonrecid)+
  geom_bar(aes(x=race,y=prop,fill=factor(score_text,levels=c("Low","Medium","High"))),
           stat="identity")+
  scale_fill_grey(start=0.8, end=0.2, name="Legend")+
  ggtitle("Proportion of Non-Recidivists by COMPAS Score")+
  xlab("Race")+
  ylab("Proportion (%)")+
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

## Criminal History

After looking at general trends in recidivists by score category and race, let's take a closer look at the criminal backgrounds of these individuals to get a better understanding of their risk scores and recidivism rates. Looking at the chart of average prior offenses below, we can see that both African-Americans and Native-Americans have high numbers of prior offenses. This conclusion is consistent with the disproportionate number of African-Americans in the US criminal justice system who are incarcerated and targeted through arguably biased policing methods. Additionally, Native-Americans are another disenfranchised population in the US demonstrating high crime rates.  

```{r,echo=FALSE}
#Adding data columns of juvenile history and priors
data <- sqldf('SELECT data.*, people.juv_fel_count, people.juv_misd_count, 
              people.juv_other_count, people.priors_count
              FROM data
              JOIN people ON data.person_id = people.person_id')

allprior <- aggregate(priors_count~race,data=data,mean)

ggplot(data=allprior)+
  geom_bar(aes(x=race,y=priors_count),
           stat="identity")+
  scale_fill_grey(start=0.8, end=0.2, name="Legend")+
  ggtitle("Average Prior Offenses By Race")+
  xlab("Race")+
  ylab("Prior Offenses (Average)")
  
```

```{r,echo=FALSE,include=FALSE}
# Looking at number of juvenile offences
juv <- subset(people,select=c("person_id","name","first","last","race",
                              "juv_fel_count","juv_misd_count","juv_other_count"))
juvtotal <- juv %>%
  group_by(person_id) %>%
  summarise(totaljuvcount=sum(juv_fel_count,juv_misd_count,juv_other_count))

juv <- sqldf("SELECT juv.*,compas.score_text
             FROM juv
             INNER JOIN compas ON juv.person_id=compas.person_id")

juv <- juv[!duplicated(juv),]
juv <- juv[!juv$race=="Other",]
juv <- juv[!is.na(juv$score_text),]

juv <- sqldf("SELECT juv.*,juvtotal.totaljuvcount
             FROM juv
             JOIN juvtotal ON juv.person_id=juvtotal.person_id")

avejuv <- aggregate(totaljuvcount~race,data=juv,mean)


```

## Juvenile Offenses

Continuing on from prior offenses, let's also look at juvenile offenses. We can see again that African-Americans and Native-Americans are the two populations with the highest number of juvenile offenses in this population. This is indicative of inadequate support systems for minority populations that begins at adolescence and continues into adulthood. 


```{r,echo=FALSE}
ggplot(data=avejuv)+
  geom_bar(aes(x=race,y=totaljuvcount),stat="identity")+
  scale_fill_grey(start=0.8, end=0.2, name="Legend")+
  ggtitle("Total Juvenile Offenses")+
  xlab("Race")+
  ylab("Number of Juvenile Offenses")


```



```{r,echo=FALSE,warning=FALSE,include=FALSE}

# Creating dataframe with relevant information
model <- people[,c("person_id","first","last")]

# Adding column with concatenated charges (if an individual has multiple charges)
cases <- casearrest[!duplicated(casearrest$person_id),]
cases <- sqldf("SELECT cases.*, A.charges
               FROM cases
               JOIN A ON cases.person_id=A.person_id")

# Jail history: finding averge time spent in jail for individuals with multiple rows of data
jailhistory$prior_time_in_jail <- as.numeric(difftime(jailhistory$out_custody,
                                                      jailhistory$in_custody,units="days"))
priorjail <- aggregate(prior_time_in_jail~person_id,data=jailhistory,sum)
colnames(priorjail) <- c("person_id","totalpriorjail")
occjail <- summarise(group_by(jailhistory,person_id), occjail=length(person_id))
jailhistory <- sqldf("SELECT jailhistory.*,priorjail.totalpriorjail, occjail.occjail
                     FROM jailhistory
                     JOIN priorjail ON jailhistory.person_id=priorjail.person_id
                     JOIN occjail ON jailhistory.person_id=occjail.person_id")
jailhistory$priorjailave <- jailhistory$totalpriorjail / jailhistory$occjail

# Prison history: same process as jail history
prisonhistory$in_custody <- as.POSIXct(as.Date(prisonhistory$in_custody))
prisonhistory$out_custody <- as.POSIXct(as.Date(prisonhistory$out_custody))
prisonhistory$time_in_prison <- as.numeric(difftime(prisonhistory$out_custody,
                                                    prisonhistory$in_custody,units="days"))

priorprison <- aggregate(time_in_prison~person_id,data=prisonhistory,sum)
colnames(priorprison) <- c("person_id","totalpriorprison")

occprison <- summarise(group_by(prisonhistory,person_id),occprison=length(person_id))

prisonhistory <- sqldf("SELECT prisonhistory.*,priorprison.totalpriorprison, occprison.occprison
                       FROM prisonhistory
                       JOIN priorprison ON prisonhistory.person_id=priorprison.person_id
                       JOIN occprison ON prisonhistory.person_id=occprison.person_id")
prisonhistory$prisonave <- prisonhistory$totalpriorprison / prisonhistory$occprison

# Compiling all relevant columns from different dataframes
model <- sqldf("SELECT model.*,cases.charges, compas_one.decile_score,
        jailhistory.priorjailave, people.race, people.priors_count, people.age,
        people.is_recid, people.sex, prisonhistory.prisonave
        FROM model
        LEFT JOIN people ON model.person_id=people.person_id
        LEFT JOIN cases ON model.person_id=cases.person_id
        LEFT JOIN compas_one ON model.person_id=compas_one.person_id
        LEFT JOIN jailhistory ON model.person_id=jailhistory.person_id
        LEFT JOIN prisonhistory ON model.person_id=prisonhistory.person_id")

model <- model[!duplicated(model$person_id),]
model <- model[!model$is_recid==-1,]
model <- model[!is.na(model$priorjailave),]

```

## Logistic Regression

To supplement our graphical exploration of recidivism, we created a logistic regression to predict recidivism using variables such as the decile COMPAS score, number of priors, age, race, and sex. Below, the model summary is shown as well as the ANOVA table and ROC curve. We can see that the AUC is 0.708.


```{r,echo=FALSE}

# Creating subset of dataframe
modeldf <- subset(model,select=c("decile_score","priors_count","age",
                                     "is_recid","race","sex"))
train <- modeldf[1:5223,]
test <- modeldf[5224:10446,]

# Logistic regression for model to predict recidivism
modeltrain <- glm(is_recid~.,family=binomial,data=test)

summary(modeltrain)

anova(modeltrain, test="Chisq")


#AUC analysis
# https://www.r-bloggers.com/evaluating-logistic-regression-models/

prob <- predict(modeltrain,newdata=test,type="response")
pred <- prediction(prob,test$is_recid)
perf <- performance(pred,measure="tpr",x.measure="fpr")
plot(perf)

auc <- performance(pred,measure="auc")
auc <- auc@y.values[[1]]
auc


```



```{r,echo=FALSE,include=FALSE}

txt <- pdf_text("Recidivism _ National Institute of Justice.pdf")
txt <- data_frame(txt)
text <-txt %>% unnest_tokens(word, txt)
data(stop_words)
text <-  text %>% 
  anti_join(stop_words)

text %>%  count(word, sort=TRUE)


```


## Recidivism: Dataframe, wordcloud and charts 
Here we analyzed documents from the National Institute of Justice about recidivism that explain what it means and why it is a concern in the criminal justice world.
We also did sentiment analysis on the above documents and an article from the Tampa Bay Times to visualize the primary words used and the sentiment of the government vs the media.


```{r,echo=FALSE,warning=FALSE}

text %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, random.color = TRUE))

text %>%
  count(word, sort = TRUE) %>%
  filter(n > 5) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

```

```{r,echo=FALSE,include=FALSE}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", 
                          "negative")) %>% 
  count(sentiment)


get_sentiments("bing") %>% 
  count(sentiment)

bing_word_counts <- text %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```


```{r,echo=FALSE}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```

## Why is recidivism a core criminal justice system concern?

```{r,echo=FALSE,include=FALSE}

txt2 <- pdf_text("Recidivism_concern.pdf")
txt2 <- data_frame(txt2)
text2 <-txt2 %>% unnest_tokens(word, txt2)
data(stop_words)
text2 <-  text2 %>% 
  anti_join(stop_words)

text2 %>%  count(word, sort=TRUE)
```


```{r,echo=FALSE}

text2 %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, random.color = TRUE))

text2 %>%
  count(word, sort = TRUE) %>%
  filter(n > 5) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r,echo=FALSE,include=FALSE}

get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", 
                          "negative")) %>% 
  count(sentiment)


get_sentiments("bing") %>% 
  count(sentiment)

bing_word_counts <- text2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```

```{r,echo=FALSE}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
```

## Tampa Bay Times: Sentiment Analysis

```{r,echo=FALSE,include=FALSE}

txt3 <- pdf_text("column.pdf")
txt3 <- data_frame(txt3)
text3 <-txt3 %>% unnest_tokens(word, txt3)
data(stop_words)
text3 <-  text3 %>% 
  anti_join(stop_words)

text3 %>%  count(word, sort=TRUE)
```


```{r,echo=FALSE,warning=FALSE}

text3 %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, random.color = TRUE))


text3 %>%
  count(word, sort = TRUE) %>%
  filter(n > 5) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r,echo=FALSE,include=FALSE}
get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", 
                          "negative")) %>% 
  count(sentiment)


get_sentiments("bing") %>% 
  count(sentiment)

bing_word_counts <- text3 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts
```

```{r,echo=FALSE,warning=FALSE}
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
```

## Summary

Thus we saw through the analysis that the contributing words here are very different from those that contributed to sentiment in the official NIJ documents

However, the number of negative words in the article was much more, although "Trump" was considered a positive word even though it was a proper noun and referred to the President

##Twitter

Here we pulled 100 tweets about recidivism from Twitter and turned them into a data frame.

```{r,echo=FALSE ,warning=FALSE }

api_key <- 	"WHvVBqFMzApGyKDDOlVurDXWn"
api_secret <- "2CKcUlOovMgrSfkrdN08RokQghD23bPGZCRd8m6mVHElj8MCFj"

access_token <- "2181030528-BoTbyeZSYIEhkEFznFMaIi8ECqBQPDfTHuqu5cN"
access_token_secret <- "XWGreeJvBp6HaIIQgY5gaZdACdkVuTnlpxPkcM20Ukc6l"



setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
1



searchTwitter('recidivism')



tweets <- searchTwitter("recidivism  OR 'repeat offenders' OR #recidivism", n=100, lang="en", since="2000-08-20")

# Transform tweets list into a data frame
tweets.df <- twListToDF(tweets)

```

